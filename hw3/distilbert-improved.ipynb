{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba19d5ae-2af8-455e-8efa-4a1cd48b466f",
   "metadata": {},
   "source": [
    "#### Name: Sai Sriharsha Griddaluru\n",
    "CUID: C15358926"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "05fce92b-b722-4d04-a813-346afe03b030",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import DistilBertForQuestionAnswering, DistilBertTokenizer\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4bac48a0-92d7-4558-b763-450ce28f1335",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# :: function to read the dataset :: \n",
    "def read_squad(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    \n",
    "    for item in data['data']:\n",
    "        for paragraph in item['paragraphs']:\n",
    "            context = paragraph['context']\n",
    "            for qa in paragraph['qas']:\n",
    "                question = qa['question']\n",
    "                answer = qa['answers'][0]  # Assuming one answer per question\n",
    "                contexts.append(context)\n",
    "                questions.append(question)\n",
    "                answers.append(answer)\n",
    "    \n",
    "    return contexts, questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c3f91ea5-2f45-46bd-b951-b635db17e80c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# :: load pre-trained model and tokenizer ::\n",
    "def load_pretrained_model(model_path, device):\n",
    "    model = DistilBertForQuestionAnswering.from_pretrained(model_path)\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(model_path)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9df6d8ba-67a1-4641-b930-642cc726ac61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# :: function to get predictions from the model :: \n",
    "# Import necessary logging module\n",
    "from transformers import logging\n",
    "\n",
    "# Set the verbosity to only show errors (this will suppress warnings and info messages)\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "def get_answer(model, tokenizer, context, question, device):\n",
    "    # Apply truncation and handle padding correctly, avoiding overflow tokens\n",
    "    \n",
    "    inputs = tokenizer(question, context, return_tensors=\"pt\", truncation=True, padding='max_length', max_length=512, return_overflowing_tokens=False)\n",
    "    \n",
    "    # Move inputs to the device (GPU or CPU)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        start_scores, end_scores = outputs.start_logits, outputs.end_logits\n",
    "        start_idx = torch.argmax(start_scores)\n",
    "        end_idx = torch.argmax(end_scores) + 1\n",
    "        answer = tokenizer.decode(inputs['input_ids'][0][start_idx:end_idx], skip_special_tokens=True)\n",
    "        \n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "585f0201-dff4-47e2-be25-f21519a27709",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 2320/2320 [06:57<00:00,  5.55it/s, loss=2.64]\n",
      "Epoch 1: 100%|██████████| 2320/2320 [06:59<00:00,  5.53it/s, loss=1.97]\n",
      "Epoch 2: 100%|██████████| 2320/2320 [06:59<00:00,  5.53it/s, loss=2.94]\n",
      "Epoch 3: 100%|██████████| 2320/2320 [06:59<00:00,  5.53it/s, loss=1.67] \n",
      "Epoch 4: 100%|██████████| 2320/2320 [06:59<00:00,  5.53it/s, loss=1.73] \n",
      "Epoch 5: 100%|██████████| 2320/2320 [06:59<00:00,  5.53it/s, loss=1.62] \n",
      "Epoch 6: 100%|██████████| 2320/2320 [06:59<00:00,  5.53it/s, loss=1.69] \n",
      "Epoch 7: 100%|██████████| 2320/2320 [07:00<00:00,  5.52it/s, loss=0.956]\n",
      "Epoch 8: 100%|██████████| 2320/2320 [07:00<00:00,  5.52it/s, loss=2.02] \n",
      "Epoch 9: 100%|██████████| 2320/2320 [07:01<00:00,  5.51it/s, loss=1.2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# :: training model :: \n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "model.train()\n",
    "optim = AdamW(model.parameters(), lr=2e-6)\n",
    "\n",
    "# initialize data loader for training data\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    for batch in loop:\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        start_positions=start_positions,\n",
    "                        end_positions=end_positions)\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6d5d8f2-eb65-4091-bf80-92a63e150f48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# :: function to calculate evaluation metrics ::\n",
    "def calculate_metrics(predictions, references):\n",
    "    em_score = np.mean([1 if pred.strip() == ref.strip() else 0 for pred, ref in zip(predictions, references)])\n",
    "    \n",
    "    f1_scores = []\n",
    "    for pred, ref in zip(predictions, references):\n",
    "        pred_tokens = pred.strip().split()\n",
    "        ref_tokens = ref.strip().split()\n",
    "        common_tokens = set(pred_tokens) & set(ref_tokens)\n",
    "        \n",
    "        if len(common_tokens) == 0:\n",
    "            f1_scores.append(0)\n",
    "        else:\n",
    "            precision = len(common_tokens) / len(pred_tokens)\n",
    "            recall = len(common_tokens) / len(ref_tokens)\n",
    "            f1_scores.append(2 * (precision * recall) / (precision + recall))\n",
    "    \n",
    "    f1_score_mean = np.mean(f1_scores)\n",
    "    return em_score * 100, f1_score_mean * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "79b39e60-3818-497f-9c48-550eb1c13421",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE PREDICTIONS:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15/5351 [00:00<00:37, 143.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTEXT: super bowl fifty was an american football game to determine the champion of the national football league nfl for the twenty fifteen season. the american football conference a f c c champion denver broncos defeated the national football conference n f c c champion carolina panthers twenty four to ten to earn their third super bowl title. the game was played on february seventh twenty sixteen and levis stadium in the san francisco bay area santa clara california. as this was the fiftieth super bowl the league emphasized the golden anniversary with various goldsteins initiatives as well as temporarily suspending the tradition of naming each super bowl game with roman numerals under which they gain would have been known as super bowl l sell that the logo could prominently featured the arabic numerals fifty.\n",
      "QUESTION: Which NFL team represented the AFC at Super Bowl 50?\n",
      "PREDICTED ANSWER: denver broncos\n",
      "ACTUAL ANSWER: denver broncos\n",
      "-----\n",
      "CONTEXT: super bowl fifty was an american football game to determine the champion of the national football league nfl for the twenty fifteen season. the american football conference a f c c champion denver broncos defeated the national football conference n f c c champion carolina panthers twenty four to ten to earn their third super bowl title. the game was played on february seventh twenty sixteen and levis stadium in the san francisco bay area santa clara california. as this was the fiftieth super bowl the league emphasized the golden anniversary with various goldsteins initiatives as well as temporarily suspending the tradition of naming each super bowl game with roman numerals under which they gain would have been known as super bowl l sell that the logo could prominently featured the arabic numerals fifty.\n",
      "QUESTION: Which NFL team represented the NFC at Super Bowl 50?\n",
      "PREDICTED ANSWER: denver broncos\n",
      "ACTUAL ANSWER: carolina panthers\n",
      "-----\n",
      "CONTEXT: super bowl fifty was an american football game to determine the champion of the national football league nfl for the twenty fifteen season. the american football conference a f c c champion denver broncos defeated the national football conference n f c c champion carolina panthers twenty four to ten to earn their third super bowl title. the game was played on february seventh twenty sixteen and levis stadium in the san francisco bay area santa clara california. as this was the fiftieth super bowl the league emphasized the golden anniversary with various goldsteins initiatives as well as temporarily suspending the tradition of naming each super bowl game with roman numerals under which they gain would have been known as super bowl l sell that the logo could prominently featured the arabic numerals fifty.\n",
      "QUESTION: Where did Super Bowl 50 take place?\n",
      "PREDICTED ANSWER: super bowl fifty\n",
      "ACTUAL ANSWER: santa clara california\n",
      "-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5351/5351 [00:37<00:00, 143.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# :: main script ::\n",
    "# load data\n",
    "train_contexts, train_questions, train_answers = read_squad('./spoken_data/spoken_train-v1.1.json')\n",
    "val_contexts, val_questions, val_answers = read_squad('./spoken_data/spoken_test-v1.1.json')\n",
    "\n",
    "\n",
    "# load pre-trained model and tokenizer\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model_path = './improved_model'  # Path where your trained model is saved\n",
    "model, tokenizer = load_pretrained_model(model_path, device)\n",
    "\n",
    "# collect predictions and references\n",
    "predictions = []\n",
    "references = [answer['text'] for answer in val_answers]  # Assuming val_answers is a list of answer dicts\n",
    "\n",
    "# generate answers and print three examples\n",
    "print(\"SAMPLE PREDICTIONS:\")\n",
    "for idx, (context, question) in enumerate(tqdm(zip(val_contexts, val_questions), total=len(val_questions))):\n",
    "    predicted_answer = get_answer(model, tokenizer, context, question, device)\n",
    "    predictions.append(predicted_answer)\n",
    "\n",
    "    # Print 3 example outputs\n",
    "    if idx < 3:\n",
    "        print(f\"CONTEXT: {context}\")\n",
    "        print(f\"QUESTION: {question}\")\n",
    "        print(f\"PREDICTED ANSWER: {predicted_answer}\")\n",
    "        print(f\"ACTUAL ANSWER: {references[idx]}\")\n",
    "        print(\"-----\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "562af046-c92a-4d56-8667-b45d276b1d51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match (EM): 13.10%\n",
      "F1 Score: 22.71%\n"
     ]
    }
   ],
   "source": [
    "# calculate and display evaluation metrics\n",
    "em, f1 = calculate_metrics(predictions, references)\n",
    "print(f\"Exact Match (EM): {em:.2f}%\")\n",
    "print(f\"F1 Score: {f1:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
